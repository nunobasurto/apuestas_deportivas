\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

En este capítulo vamos a abordar todo lo concerniente al proyecto. Es un resumen de como se ha llevado a cabo el proyecto.
\section{Lenguaje para el desarrollo del proyecto}

Desde un primer momento se decidió el empleo de PHP como lenguaje central en la implementación del proyecto dado que permite el desarrollo web de contenido dinámico. El proyecto se ha llevado a cabo con Sublime Text, lo cual ha permitido una implementación del código más sencilla ya que iba mostrando posibles predicciones de texto.

PHP ha hecho posible aplicar alguna técnica de programación orientada a objetos, que se puede observar en el código del algoritmo de Backpropagation donde existen dos clases.
Se barajó la opción de implementar el código en Python y dejarlo embebido sobre PHP pero la idea inicial se descartó debido a que algunas funciones como las de acceso a la base de datos son únicas desde Drupal.

\subsection{PHP en Drupal}
La base de datos de MySQL estaba vinculada con Drupal, por lo que existe acceso desde Drupal a la base de datos. Para el acceso, el código PHP debía tener algunas sentencias exclusivas. La función db\_query tiene una sintaxis similar a las que se conocen ya que el contenido es una consulta MySQL sencilla. En cambio, otras funciones como db\_update, db\_select o db\_insert tienen una estructura completamente diferentes a las conocidas aunque son sencillas de utilizar.

Para poder desarrollar todo el código sobre Sublime Text y que no hubiese necesidad de copiarlo continuamente en los nodos de Drupal, fue necesario añadir un inclue\_once tanto en el nodo de Drupal como en el script.

\section{Datos de entrada a la red neuronal}
Es preciso darle un sentido a los datos que se han ido recopilando mediante los algoritmos de scraping, ya que el objetivo es darle a la red neuronal unos datos a partir de los cuales pueda ir aprendiendo y encontrar patrones. Son dos los algoritmos de scraping que fueron recopilando los datos que más tarde han sido empleados como entrada a la red Neuronal.

El primer algoritmo extrae todas las estadísticas de cada uno de los partidos de una jornada y los almacena en la base de datos. El segundo extrae la posición y las estadísticas de cada equipo en cada jornada, para almacenarlos posteriormente en la base de datos. A partir de estos datos recopilados se calculan las rachas de los equipos, donde se tiene en cuenta los puntos de cada equipo en las últimas jornadas acontecidas, los goles a favor y  los goles en contra. De esta forma se favorece al algoritmo para conocer la tendencia del equipo en las últimas jornadas. 

En el entrenamiento, por cada una de las instancias se le pasan al algoritmo un total de 78 columnas, donde las 30 primeras contienen los estadísticas del partido, de la 30 a la 54 las rachas y las estadísticas del equipo local en la clasificación y de la 54 a la 78 lo correspondiente al equipo visitante. Como función objetivo se establece 0 si ganó el equipo local, 1 si ganó el equipo visitante y 0.5 si el resultado final fue empate.
Antes de la entrada de los datos al algoritmo se realiza una normalización de los mismos respecto a la misma columna del resto de instancias, siendo la normalización:
\begin{center}
\large{$$v' = \frac{v-min_{a}}{max_{a}-min_{a}}$$}
\end{center}

En un primer momento se pensó introducir todos los partidos anteriores como instancias, independientemente el equipo hubiese disputado el partido como local o como visitante, para diferenciarlo se establecía un campo en la tabla \textit{clasificacion\_jornada}, llamado \textit{local\_visitante}, este campo se encuentra a 0 si el equipo juega como local o 1 si juega como visitante. Dado que los resultados obtenidos no eran muy bueno se planteó otra posibilidad, si el equipo iba a disputar el partido como local se tomaban únicamente los datos de os partidos como local para ese equipo y para el rival lo mismo, se iban a tomar los datos como visitante.

Se realizó un estudio de tres jornada, en concreto la 12, 13 y 14, para elegir una u otra, en estas tablas \ref{tabla:jornada12}, \ref{tabla:jornada13} y \ref{tabla:jornada14} podemos observar los resultados obtenidos en los algoritmos, \textit{Pronóstico 1} es el primer método nombrado donde se utilizaban todos los partidos, el segundo método donde se diferenciaba local y visitante es \textit{Pronóstico 2}.

Una vez analizados los datos vemos como es el segundo método el que consigue mejores resultados.
 \begin{table}
  \begin{center}
   \begin{tabular}{|p{5cm} | p{2.5cm} |p{2.5cm} |p{2.5cm} |}
    \hline
   	Jornada 12 & Resultado & Pronostico 1 & Pronostico 2\\
    \hline
    Alaves - Espanyol & 0-1 & \cellcolor{red}1 & \cellcolor{green}2\\
    \hline
    Athletic - Villareal & 1-0 & \cellcolor{red}X & \cellcolor{red}2\\
    \hline
    Barcelona - Málaga & 0-0 & \cellcolor{red}1 & \cellcolor{green}X\\
    \hline
    Deportivo - Sevilla & 2-3 & \cellcolor{red}1 & \cellcolor{red}X\\
    \hline
    Valencia - Granada & 1-1 & \cellcolor{green}X & \cellcolor{green}X\\
    \hline
    Betis - Las Palmas & 2-0 & \cellcolor{red}X & \cellcolor{red}X\\
    \hline
    Atletico - Real Madrid & 0-3 & \cellcolor{red}1 & \cellcolor{green}2\\
    \hline
    Sporting - Real Sociedad & 1-3 & \cellcolor{red}1 & \cellcolor{green}2\\
    \hline
	Eibar - Celta & 1-0 & \cellcolor{green}1 & \cellcolor{green}1\\
    \hline
    Leganés - Osasuna & 2-0 & \cellcolor{red}X & \cellcolor{red}X\\
    \hline
   \end{tabular}
   \caption{Pruebas jornada 12.}
   \label{tabla:jornada12}
  \end{center}
 \end{table} 

 \begin{table}
  \begin{center}
   \begin{tabular}{|p{5cm} | p{2.5cm} |p{2.5cm} |p{2.5cm} |}
    \hline
   	Jornada 13 & Resultado & Pronostico 1 & Pronostico 2\\
    \hline
    Celta - Granada & 3-1 & \cellcolor{green}1 & \cellcolor{green}1\\
    \hline
    Espanyol - Leganés & 3-0 & \cellcolor{green}1 & \cellcolor{green}1\\
    \hline
    Málaga - Deportivo & 4-3 & \cellcolor{red}2 & \cellcolor{green}1\\
    \hline
    Osasuna - Atlético & 0-3 & \cellcolor{green}2 & \cellcolor{red}X\\
    \hline
    Real Madrid - Sporting & 2-1 & \cellcolor{red}X & \cellcolor{green}1\\
    \hline
    Real Sociedad - Barcelona & 1-1 & \cellcolor{red}2 & \cellcolor{red}2\\
    \hline
    Villareal - Alavés & 0-2 & \cellcolor{red}X & \cellcolor{red}1\\
    \hline
	Sevilla - Valencia & 2-1 & \cellcolor{red}X & \cellcolor{green}1\\
    \hline
	Eibar - Betis & 3-1 & \cellcolor{green}1 & \cellcolor{green}1\\
    \hline
    Las Palmas - Athletic & 3-1 & \cellcolor{red}X & \cellcolor{red}1\\
    \hline
   \end{tabular}
   \caption{Pruebas jornada 13.}
   \label{tabla:jornada13}
  \end{center}
 \end{table} 
 
  \begin{table}
  \begin{center}
   \begin{tabular}{|p{5cm} | p{2.5cm} |p{2.5cm} |p{2.5cm} |}
    \hline
   	Jornada 14 & Resultado & Pronostico 1 & Pronostico 2\\
    \hline
    Alaves - Las Palmas & 1-1 & \cellcolor{green}X & \cellcolor{green}X\\
    \hline
    Athletic - Eibar & 3-1 & \cellcolor{green}1 & \cellcolor{red}X\\
    \hline
    Barcelona - Real Madrid & 1-1 & \cellcolor{green}X & \cellcolor{red}2\\
    \hline
    Deportivo - Real Sociedad & 5-1 & \cellcolor{red}X & \cellcolor{red}2\\
    \hline
    Valencia - Málaga & 2-2 & \cellcolor{red}2 & \cellcolor{red}2\\
    \hline
    Betis - Celta & 3-3 & \cellcolor{green}X & \cellcolor{green}X\\
    \hline
    Atletico - Espanyol & 0-0 & \cellcolor{red}2 & \cellcolor{green}1\\
    \hline
    Sporting - Osasuna & 3-1 & \cellcolor{red}X & \cellcolor{green}1\\
    \hline
	Granada - Sevilla & 2-1 & \cellcolor{red}X & \cellcolor{red}2\\
    \hline
    Leganés - Villareal & 0-0 & \cellcolor{red}1 & \cellcolor{green}X\\
    \hline
   \end{tabular}
   \caption{Pruebas jornada 14.}
   \label{tabla:jornada14}
  \end{center}
 \end{table} 

\section{Optimización del algoritmo de Backpropagation}
Cuando los datos se encuentran en la red neuronal es preciso optimizar el número de neuronas que se van a utilizar. Con un número de neuronas pequeño, la red neuronal puede ser incapaz de aprender todos los patrones existentes, teniendo problemas para devolver la salida deseada. En cambio, si el número de neuronas es demasiado grande, la red neuronal se queda sin margen de adaptación a cambios.

Otro factor a tener en cuenta son las iteraciones que van a ejecutarse, ya que ante un pequeño número el algoritmo puede no aprender suficiente, y si el número es muy alto termina memorizando cada una. Esto supone que no se logren los resultados deseados en el test, por lo que se ha llevado a cabo un estudio para determinar cual es la cantidad más adecuada de neuronas y de epochs para el aprendizaje de la red neuronal.

Se utilizó la jornada 14 para ver como realizar el ajuste de la red neuronal, extraíamos el error que nos encontrábamos realizando el training, en esta tabla podemos observar el error obtenido.



TABLA


\section{Interfaz sencilla para el usuario}

Con todos los datos necesarios es importante conocer cómo mostrarlos al usuario que accede al sitio web. Dado que el objetivo de esta página es su uso con apuestas deportivas, se ha hecho un algoritmo de scraping que recopila las cuotas de las casas de apuestas para cada partido.
A partir de los resultados que se han predicho, se muestran las cuotas de las cuatro casas de apuestas principales en España, ofreciendo al usuario la posibilidad de apostar en ellas.
En una de la páginas del sitio web se puede observar el balance general a lo largo de la temporada, donde es posible acceder a cada una de las jornadas y ver más detalladamente lo ocurrido a lo largo de la temporada.

\section{Automatización del funcionamiento}

Dado que la obtención de datos debe hacerse periódicamente y la ejecución manual por parte del usuario es tediosa, se ha automatizado la ejecución de todos los algoritmos en base al momento en el que deban ejecutarse. Por ejemplo, solo es posible obtener los resultados de una jornada una vez finalizada esta, o es posible fijarse en las cuotas de las casas de apuestas, las cuales pueden ir variando a lo largo de la semana debido a que no son valores fijos.

Para cada jornada se establece una fecha\_antes y una fecha\_despues, los algoritmos de scraping de resultados se ejecutan una vez finalizada la jornada, es decir, si son posteriores a fecha\_despues, algo similar ocurre con el scraping de casas de apuestas solo que en este caso lo mejor es obtener los datos justo antes de la jornada para tener los datos más recientes. Para el algoritmo de backpropagation no es necesario el día exacto en el que ejecutarse, pero debe ejecutarse siempre una vez finalizada la jornada anterior, ya que son necesarias las rachas y los datos de la pasada jornada.

Todo esto lo logramos gracias al uso de demonios, también llamados servicios, que comparan la fecha actual a la fecha de la jornada, ya sea la anterior o posterior, y en caso de coincidir ejecutan el algoritmo deseado. El demonio se ejecuta todos los dias a la misma hora esto se debe a que no todas las jornadas comienzan el viernes y acaban el Lunes si no que algunas jornadas se disputan entre semana.