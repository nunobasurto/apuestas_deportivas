
@misc{_sublime_2016,
	title = {Sublime {Text}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://es.wikipedia.org/w/index.php?title=Sublime_Text&oldid=93935858},
	abstract = {Sublime Text es un editor de texto y editor de código fuente está escrito en C++ y Python para los plugins. Desarrollado originalmente como una extensión de Vim, con el tiempo fue creando una identidad propia, por esto aún conserva un modo de edición tipo vi llamado Vintage mode.
Se puede descargar y evaluar de forma gratuita. Sin embargo no es software libre o de código abierto y se debe obtener una licencia para su uso continuado, aunque la versión de evaluación es plenamente funcional y no tiene fecha de caducidad.},
	language = {es},
	urldate = {2016-12-21},
	journal = {Wikipedia, la enciclopedia libre},
	month = sep,
	year = {2016},
	note = {Page Version ID: 93935858},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\JGJ23EEF\\index.html:text/html}
}

@misc{_comparativa_????,
	title = {Comparativa {Drupal}, {Joomla} y {Wordpress} {\textbar} {Programación} {Web} {Drupal}},
	url = {http://www.isyourweb.com/comparativa-drupal-joomla-y-wordpress},
	urldate = {2016-12-21},
	file = {Comparativa Drupal, Joomla y Wordpress | Programación Web Drupal:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\QEGM6Z2H\\comparativa-drupal-joomla-y-wordpress.html:text/html}
}

@misc{_servidor_2016,
	title = {Servidor {HTTP} {Apache}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://es.wikipedia.org/w/index.php?title=Servidor_HTTP_Apache&oldid=91988556},
	abstract = {El servidor HTTP Apache es un servidor web HTTP de código abierto, para plataformas Unix (BSD, GNU/Linux, etc.), Microsoft Windows, Macintosh y otras, que implementa el protocolo HTTP/1.1 y la noción de sitio virtual. Cuando comenzó su desarrollo en 1995 se basó inicialmente en código del popular NCSA HTTPd 1.3, pero más tarde fue reescrito por completo. Su nombre se debe a que alguien quería que tuviese la connotación de algo que es firme y enérgico pero no agresivo, y la tribu Apache fue la última en rendirse al que pronto se convertiría en gobierno de EEUU, y en esos momentos la preocupación de su grupo era que llegasen las empresas y "civilizasen" el paisaje que habían creado los primeros ingenieros de internet. Además Apache consistía solamente en un conjunto de parches a aplicar al servidor de NCSA. En inglés, a patchy server (un servidor "parcheado") suena igual que Apache Server.
El servidor Apache es desarrollado y mantenido por una comunidad de usuarios bajo la supervisión de la Apache Software Foundation dentro del proyecto HTTP Server (httpd).
Apache presenta entre otras características altamente configurables, bases de datos de autenticación y negociado de contenido, pero fue criticado por la falta de una interfaz gráfica que ayude en su configuración.
Apache tiene amplia aceptación en la red: desde 1996, Apache, es el servidor HTTP más usado. Jugó un papel fundamental en el desarrollo fundamental de la World Wide Web y alcanzó su máxima cuota de mercado en 2005 siendo el servidor empleado en el 70\% de los sitios web en el mundo, sin embargo ha sufrido un descenso en su cuota de mercado en los últimos años. (Estadísticas históricas y de uso diario proporcionadas por Netcraft ). En 2009 se convirtió en el primer servidor web que alojó más de 100 millones de sitios web .
La mayoría de las vulnerabilidades de la seguridad descubiertas y resueltas tan sólo pueden ser aprovechadas por usuarios locales y no remotamente. Sin embargo, algunas se pueden accionar remotamente en ciertas situaciones, o explotar por los usuarios locales malévolos en las disposiciones de recibimiento compartidas que utilizan PHP como módulo de Apache.},
	language = {es},
	urldate = {2016-12-21},
	journal = {Wikipedia, la enciclopedia libre},
	month = jun,
	year = {2016},
	note = {Page Version ID: 91988556},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\HRUKN2V6\\index.html:text/html}
}

@misc{_lamp_2016,
	title = {{LAMP}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://es.wikipedia.org/w/index.php?title=LAMP&oldid=94265579},
	abstract = {LAMP es el acrónimo usado para describir un sistema de infraestructura de internet que usa las siguientes herramientas:
Linux, el sistema operativo; En algunos casos también se refiere a LDAP.
Apache, el servidor web;
MySQL/MariaDB, el gestor de bases de datos;
Perl, PHP, o Python, los lenguajes de programación.
La combinación de estas tecnologías es usada principalmente para definir la infraestructura de un servidor web, utilizando un paradigma de programación para el desarrollo.
A pesar de que el origen de estos programas de código abierto no han sido específicamente diseñado para trabajar entre sí, la combinación se popularizó debido a su bajo coste de adquisición y ubicuidad de sus componentes (ya que vienen pre-instalados en la mayoría de las distribuciones linux). Cuando son combinados, representan un conjunto de soluciones que soportan servidores de aplicaciones.
Ampliamente promocionado por el editor de la editorial O'Reilly, Dale Dougherty, a sugerencia de David Axmark y Monty Widenius desarrolladores de MySQL, la influencia de la editorial O'Reilly en el mundo del software libre hizo que el término se popularizara rápidamente en todo el mundo.},
	language = {es},
	urldate = {2017-01-04},
	journal = {Wikipedia, la enciclopedia libre},
	month = oct,
	year = {2016},
	note = {Page Version ID: 94265579},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\4ZZAEXAC\\index.html:text/html}
}

@misc{alejandrocassis_aprendizaje_2015,
	title = {Aprendizaje {Supervisado}},
	url = {https://inteligenciaartificial101.wordpress.com/2015/10/20/aprendizaje-supervisado/},
	abstract = {En este post, explicaré de forma general la tarea del Aprendizaje Supervisado. Además, introduciré cierta notación para que sea más sencillo elaborar sobre estos conceptos posteriormente. (Me refer…},
	urldate = {2016-12-26},
	journal = {Inteligencia Artificial 101},
	author = {Alejandrocassis},
	month = oct,
	year = {2015},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\2SBZJAVX\\aprendizaje-supervisado.html:text/html}
}

@misc{_acerca_????,
	title = {Acerca de {Trello}},
	url = {https://trello.com/about},
	urldate = {2016-12-22},
	file = {Acerca de Trello:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\AEVPQV66\\about.html:text/html}
}

@incollection{garcia_introduction_2015,
	series = {Intelligent {Systems} {Reference} {Library}},
	title = {Introduction},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-10246-7 978-3-319-10247-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-10247-4_1},
	abstract = {The main background addressed in this book should be presented regarding Data Mining and Knowledge Discovery. Major concepts used throughout the contents of the rest of the book will be introduced, such as learning models, strategies and paradigms, etc. Thus, the whole process known as Knowledge Discovery in Data is provided in Sect. 1.1. A review on the main models of Data Mining is given in Sect. 1.2, accompanied a clear differentiation between Supervised and Unsupervised learning (Sects. 1.3 and 1.4, respectively). In Sect. 1.5, apart from the two classical data mining tasks, we mention other related problems that assume more complexity or hybridizations with respect to the classical learning paradigms. Finally, we establish the relationship between Data Preprocessing with Data Mining in Sect. 1.6.},
	language = {en},
	number = {72},
	urldate = {2017-01-09},
	booktitle = {Data {Preprocessing} in {Data} {Mining}},
	publisher = {Springer International Publishing},
	author = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	year = {2015},
	note = {DOI: 10.1007/978-3-319-10247-4\_1},
	keywords = {Computational Intelligence, Data Mining and Knowledge Discovery, Image Processing and Computer Vision},
	pages = {1--17},
	file = {Full Text PDF:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\JBBKG8IA\\García et al. - 2015 - Introduction.pdf:application/pdf;Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\62JM4IMG\\978-3-319-10247-4_1.html:text/html}
}

@misc{_wordpress_2016,
	title = {{WordPress}, {Drupal} o {Joomla}. ¿{Cuál} es mejor?},
	url = {https://neliosoftware.com/es/blog/wordpress-drupal-joomla-mejor/},
	abstract = {Analizamos las virtudes y defectos de WordPress, Drupal y Joomla para decidir cuál es el mejor gestor de contenidos que puedes escoger para lanzar tu web.},
	urldate = {2016-12-22},
	journal = {Nelio Software},
	month = jan,
	year = {2016},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\88A4FDT3\\wordpress-drupal-joomla-mejor.html:text/html}
}

@incollection{garcia_data_2015,
	series = {Intelligent {Systems} {Reference} {Library}},
	title = {Data {Sets} and {Proper} {Statistical} {Analysis} of {Data} {Mining} {Techniques}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-10246-7 978-3-319-10247-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-10247-4_2},
	abstract = {Presenting a Data Mining technique and analyzing it often involves using a data set related to the domain. In research fortunately many well-known data sets are available and widely used to check the performance of the technique being considered. Many of the subsequent sections of this book include a practical experimental comparison of the techniques described in each one as a exemplification of this process. Such comparisons require a clear bed test in order to enable the reader to be able to replicate and understand the analysis and the conclusions obtained. First we provide an insight of the data sets used to study the algorithms presented as representative in each section in Sect. 2.1. In this section we elaborate on the data sets used in the rest of the book indicating their characteristics, sources and availability. We also delve in the partitioning procedure and how it is expected to alleviate the problematic associated to the validation of any supervised method as well as the details of the performance measures that will be used in the rest of the book. Section 2.2 takes a tour of the most common statistical techniques required in the literature to provide meaningful and correct conclusions. The steps followed to correctly use and interpret the statistical test outcome are also given.},
	language = {en},
	number = {72},
	urldate = {2017-01-09},
	booktitle = {Data {Preprocessing} in {Data} {Mining}},
	publisher = {Springer International Publishing},
	author = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	year = {2015},
	note = {DOI: 10.1007/978-3-319-10247-4\_2},
	keywords = {Computational Intelligence, Data Mining and Knowledge Discovery, Image Processing and Computer Vision},
	pages = {19--38},
	file = {Full Text PDF:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\RKCIPRQK\\García et al. - 2015 - Data Sets and Proper Statistical Analysis of Data .pdf:application/pdf;Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\H99MAZQS\\978-3-319-10247-4_2.html:text/html}
}

@misc{_diseno_????,
	title = {Diseño {Web} {Centrado} en el {Usuario}: {Usabilidad} y {Arquitectura} de la {Información}},
	shorttitle = {Diseño {Web} {Centrado} en el {Usuario}},
	url = {http://www.upf.edu/hipertextnet/numero-2/diseno_web.html},
	urldate = {2017-01-09},
	journal = {Hipertext},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\FCA2ZIJ9\\diseno_web.html:text/html}
}

@misc{_propagacion_2016,
	title = {Propagación hacia atrás},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://es.wikipedia.org/w/index.php?title=Propagaci%C3%B3n_hacia_atr%C3%A1s&oldid=92429003},
	abstract = {La propagación hacia atrás de errores o retropropagación (del inglés backpropagation) es un algoritmo de aprendizaje supervisado que se usa para entrenar redes neuronales artificiales. El algoritmo emplea un ciclo propagación – adaptación de dos fases. Una vez que se ha aplicado un patrón a la entrada de la red como estímulo, este se propaga desde la primera capa a través de las capas superiores de la red, hasta generar una salida. La señal de salida se compara con la salida deseada y se calcula una señal de error para cada una de las salidas.
Las salidas de error se propagan hacia atrás, partiendo de la capa de salida, hacia todas las neuronas de la capa oculta que contribuyen directamente a la salida. Sin embargo las neuronas de la capa oculta solo reciben una fracción de la señal total del error, basándose aproximadamente en la contribución relativa que haya aportado cada neurona a la salida original. Este proceso se repite, capa por capa, hasta que todas las neuronas de la red hayan recibido una señal de error que describa su contribución relativa al error total.
La importancia de este proceso consiste en que, a medida que se entrena la red, las neuronas de las capas intermedias se organizan a sí mismas de tal modo que las distintas neuronas aprenden a reconocer distintas características del espacio total de entrada. Después del entrenamiento, cuando se les presente un patrón arbitrario de entrada que contenga ruido o que esté incompleto, las neuronas de la capa oculta de la red responderán con una salida activa si la nueva entrada contiene un patrón que se asemeje a aquella característica que las neuronas individuales hayan aprendido a reconocer durante su entrenamiento.},
	language = {es},
	urldate = {2016-12-22},
	journal = {Wikipedia, la enciclopedia libre},
	month = jul,
	year = {2016},
	note = {Page Version ID: 92429003},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\DZ5HWQB4\\index.html:text/html}
}

@misc{_zotero_????,
	title = {Zotero {\textbar} {Home}},
	url = {https://www.zotero.org/},
	urldate = {2016-12-22},
	file = {Zotero | Home:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\44KXNVQZ\\www.zotero.org.html:text/html}
}

@misc{_web_2016,
	title = {Web scraping},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://es.wikipedia.org/w/index.php?title=Web_scraping&oldid=94838651},
	abstract = {Web scraping es una técnica utilizada mediante programas de software para extraer información de sitios web. Usualmente, estos programas simulan la navegación de un humano en la World Wide Web ya sea utilizando el protocolo HTTP manualmente, o incrustando un navegador en una aplicación.
El web scraping está muy relacionado con la indexación de la web, la cual indexa la información de la web utilizando un robot y es una técnica universal adoptada por la mayoría de los motores de búsqueda. Sin embargo, el web scraping se enfoca más en la transformación de datos sin estructura en la web (como el formato HTML) en datos estructurados que pueden ser almacenados y analizados en una base de datos central, en una hoja de cálculo o en alguna otra fuente de almacenamiento. El término web scraping también está relacionado con la automatización de tareas en la Web, la cual simula la navegación de un humano utilizando un software de computadora. Alguno de los usos del web scraping son la comparación de precios en tiendas, la monitorización de datos relacionados con el clima de cierta región, la detección de cambios en sitios webs y la integración de datos en sitios webs. También es utilizado para obtener información relevante de un sitio a través de los rich snippets.
En los últimos años el web scraping se ha convertido en una técnica muy utilizada dentro del sector del posicionamiento web gracias a su capacidad de generar grandes cantidades de datos para crear contenidos de calidad.},
	language = {es},
	urldate = {2016-12-22},
	journal = {Wikipedia, la enciclopedia libre},
	month = nov,
	year = {2016},
	note = {Page Version ID: 94838651},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\DSWX5QPC\\index.html:text/html}
}

@misc{_conceptos_2014,
	title = {Conceptos básicos de {Machine} {Learning} -},
	url = {http://cleverdata.io/conceptos-basicos-machine-learning/},
	abstract = {¿Te gusta compartir?},
	urldate = {2016-12-26},
	month = jul,
	year = {2014},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\NSX5X8Q3\\conceptos-basicos-machine-learning.html:text/html}
}

@misc{_oracle_????,
	title = {Oracle {VM} {VirtualBox}},
	url = {https://www.virtualbox.org/},
	urldate = {2016-12-22},
	file = {Oracle VM VirtualBox:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\GP5EW4KT\\www.virtualbox.org.html:text/html}
}

@misc{mazur_step_2015,
	title = {A {Step} by {Step} {Backpropagation} {Example}},
	url = {https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/},
	abstract = {Background Backpropagation is a common method for training a neural network. There is no shortage of papers online that attempt to explain how backpropagation works, but few that include an example…},
	urldate = {2016-12-26},
	journal = {Matt Mazur},
	author = {{Mazur}},
	month = mar,
	year = {2015},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\HC2PXG3Q\\a-step-by-step-backpropagation-example.html:text/html}
}

@misc{torres_servicios_2013,
	title = {Servicios y demonios en {Linux}},
	url = {https://jmtorres.webs.ull.es/me/2013/05/servicios-y-demonios-en-linux/},
	abstract = {En UNIX y en Linux un demonio o servicio es un programa que se ejecuta en segundo plano, fuera del control interactivo de los usuarios del sistema.},
	urldate = {2017-01-02},
	journal = {Jesús Torres},
	author = {Torres, Jesús},
	month = may,
	year = {2013},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\V94J7EE4\\servicios-y-demonios-en-linux.html:text/html}
}

@misc{contributors_phpmyadmin_????,
	title = {{phpMyAdmin}},
	url = {https://www.phpmyadmin.net/},
	urldate = {2016-12-22},
	journal = {phpMyAdmin},
	author = {contributors, phpMyAdmin},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\WQCEI8ED\\www.phpmyadmin.net.html:text/html}
}

@misc{_drupal_2016,
	title = {Drupal - {Open} {Source} {CMS}},
	url = {https://www.drupal.org/},
	abstract = {Drupal is an open source platform for building amazing digital experiences. It's made by a dedicated community. Anyone can use it, and it will always be free.},
	urldate = {2016-12-22},
	journal = {Drupal.org},
	month = sep,
	year = {2016},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\BDVPPKS8\\www.drupal.org.html:text/html}
}

@incollection{garcia_data_2015-1,
	series = {Intelligent {Systems} {Reference} {Library}},
	title = {Data {Preparation} {Basic} {Models}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-10246-7 978-3-319-10247-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-10247-4_3},
	abstract = {The basic preprocessing steps carried out in Data Mining convert real-world data to a computer readable format. An overall overview related to this topic is given in Sect. 3.1. When there are several or heterogeneous sources of data, an integration of the data is needed to be performed. This task is discussed in Sect. 3.2. After the data is computer readable and constitutes an unique source, it usually goes through a cleaning phase where the data inaccuracies are corrected. Section 3.3 focuses in the latter task. Finally, some Data Mining applications involve some particular constraints like ranges for the data features, which may imply the normalization of the features (Sect. 3.4) or the transformation of the features of the data distribution (Sect. 3.5).},
	language = {en},
	number = {72},
	urldate = {2017-01-09},
	booktitle = {Data {Preprocessing} in {Data} {Mining}},
	publisher = {Springer International Publishing},
	author = {García, Salvador and Luengo, Julián and Herrera, Francisco},
	year = {2015},
	note = {DOI: 10.1007/978-3-319-10247-4\_3},
	keywords = {Computational Intelligence, Data Mining and Knowledge Discovery, Image Processing and Computer Vision},
	pages = {39--57},
	file = {Full Text PDF:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\N66B3D89\\García et al. - 2015 - Data Preparation Basic Models.pdf:application/pdf;Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\X7433Z4C\\978-3-319-10247-4_3.html:text/html}
}

@misc{monografias.com_redes_????,
	title = {Redes neuronales artificiales - fundamentos, modelos y aplicaciones - {Monografias}.com},
	url = {http://www.monografias.com/trabajos12/redneur/redneur.shtml},
	abstract = {Panorama Histórico. El Modelo Biológico. Elementos de una Red Neuronal...},
	urldate = {2017-01-09},
	author = {Monografias.com, 1800059},
	file = {Snapshot:C\:\\Users\\nuno-\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8hcgm6ds.default\\zotero\\storage\\7A2B2HHF\\redneur.html:text/html}
}

